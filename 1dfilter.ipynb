{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1d filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Conv1d, Sequential, Module\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building a convolutional network \n",
    "\n",
    "1D CNN; filter has fixed weights generated by fortran code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chanl_in = 1 # n_loc\n",
    "chanl_out = 10 # n_loc\n",
    "# thus our filter size is 1x10x10\n",
    "# filter = a_filter -> returned by fortran code\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() \n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            Conv1d(chanl_in,chanl_out, kernel_size=7,bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(42)\n",
    "net = Net()\n",
    "\n",
    "input = torch.randn(1, 1, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2890,  0.3137, -0.0885,  0.3472, -0.0828,  0.0763, -0.1840]],\n",
      "\n",
      "        [[ 0.2220,  0.3332, -0.2773,  0.3285,  0.0707,  0.2792,  0.0512]],\n",
      "\n",
      "        [[ 0.1822, -0.0534,  0.2914,  0.0559, -0.1764,  0.0963, -0.1741]],\n",
      "\n",
      "        [[-0.0443, -0.1535,  0.2507, -0.2984, -0.1742, -0.1067, -0.2273]],\n",
      "\n",
      "        [[ 0.0357, -0.3733,  0.3413, -0.3211,  0.2918,  0.0629, -0.1227]],\n",
      "\n",
      "        [[ 0.2336,  0.0589,  0.3054,  0.0413, -0.1192,  0.1016, -0.1025]],\n",
      "\n",
      "        [[ 0.1591,  0.3375,  0.2185, -0.1652,  0.2182,  0.0676,  0.1919]],\n",
      "\n",
      "        [[-0.2304, -0.3742, -0.1460, -0.2899,  0.3101,  0.1089,  0.1566]],\n",
      "\n",
      "        [[ 0.1195, -0.0066,  0.2958, -0.2685,  0.0238, -0.2580,  0.1165]],\n",
      "\n",
      "        [[-0.1302,  0.1158, -0.0787,  0.3135, -0.2240, -0.2254, -0.2254]]])\n",
      "torch.Size([10, 1, 7])\n",
      "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
      "tensor([[ 0.6708,  0.6708,  0.6708,  0.6708,  1.0076,  1.0076,  1.0076,  1.0076,\n",
      "          0.2219,  0.2219,  0.2219,  0.2219, -0.7537, -0.7537, -0.7537, -0.7537,\n",
      "         -0.0854, -0.0854, -0.0854, -0.0854,  0.5190,  0.5190,  0.5190,  0.5190,\n",
      "          1.0275,  1.0275,  1.0275,  1.0275, -0.4649, -0.4649, -0.4649, -0.4649,\n",
      "          0.0226,  0.0226,  0.0226,  0.0226, -0.4545, -0.4545, -0.4545, -0.4545],\n",
      "        [ 0.6708,  0.6708,  0.6708,  0.6708,  1.0076,  1.0076,  1.0076,  1.0076,\n",
      "          0.2219,  0.2219,  0.2219,  0.2219, -0.7537, -0.7537, -0.7537, -0.7537,\n",
      "         -0.0854, -0.0854, -0.0854, -0.0854,  0.5190,  0.5190,  0.5190,  0.5190,\n",
      "          1.0275,  1.0275,  1.0275,  1.0275, -0.4649, -0.4649, -0.4649, -0.4649,\n",
      "          0.0226,  0.0226,  0.0226,  0.0226, -0.4545, -0.4545, -0.4545, -0.4545],\n",
      "        [ 0.6708,  0.6708,  0.6708,  0.6708,  1.0076,  1.0076,  1.0076,  1.0076,\n",
      "          0.2219,  0.2219,  0.2219,  0.2219, -0.7537, -0.7537, -0.7537, -0.7537,\n",
      "         -0.0854, -0.0854, -0.0854, -0.0854,  0.5190,  0.5190,  0.5190,  0.5190,\n",
      "          1.0275,  1.0275,  1.0275,  1.0275, -0.4649, -0.4649, -0.4649, -0.4649,\n",
      "          0.0226,  0.0226,  0.0226,  0.0226, -0.4545, -0.4545, -0.4545, -0.4545],\n",
      "        [ 0.6708,  0.6708,  0.6708,  0.6708,  1.0076,  1.0076,  1.0076,  1.0076,\n",
      "          0.2219,  0.2219,  0.2219,  0.2219, -0.7537, -0.7537, -0.7537, -0.7537,\n",
      "         -0.0854, -0.0854, -0.0854, -0.0854,  0.5190,  0.5190,  0.5190,  0.5190,\n",
      "          1.0275,  1.0275,  1.0275,  1.0275, -0.4649, -0.4649, -0.4649, -0.4649,\n",
      "          0.0226,  0.0226,  0.0226,  0.0226, -0.4545, -0.4545, -0.4545, -0.4545],\n",
      "        [ 0.6708,  0.6708,  0.6708,  0.6708,  1.0076,  1.0076,  1.0076,  1.0076,\n",
      "          0.2219,  0.2219,  0.2219,  0.2219, -0.7537, -0.7537, -0.7537, -0.7537,\n",
      "         -0.0854, -0.0854, -0.0854, -0.0854,  0.5190,  0.5190,  0.5190,  0.5190,\n",
      "          1.0275,  1.0275,  1.0275,  1.0275, -0.4649, -0.4649, -0.4649, -0.4649,\n",
      "          0.0226,  0.0226,  0.0226,  0.0226, -0.4545, -0.4545, -0.4545, -0.4545],\n",
      "        [ 0.6708,  0.6708,  0.6708,  0.6708,  1.0076,  1.0076,  1.0076,  1.0076,\n",
      "          0.2219,  0.2219,  0.2219,  0.2219, -0.7537, -0.7537, -0.7537, -0.7537,\n",
      "         -0.0854, -0.0854, -0.0854, -0.0854,  0.5190,  0.5190,  0.5190,  0.5190,\n",
      "          1.0275,  1.0275,  1.0275,  1.0275, -0.4649, -0.4649, -0.4649, -0.4649,\n",
      "          0.0226,  0.0226,  0.0226,  0.0226, -0.4545, -0.4545, -0.4545, -0.4545],\n",
      "        [ 0.6708,  0.6708,  0.6708,  0.6708,  1.0076,  1.0076,  1.0076,  1.0076,\n",
      "          0.2219,  0.2219,  0.2219,  0.2219, -0.7537, -0.7537, -0.7537, -0.7537,\n",
      "         -0.0854, -0.0854, -0.0854, -0.0854,  0.5190,  0.5190,  0.5190,  0.5190,\n",
      "          1.0275,  1.0275,  1.0275,  1.0275, -0.4649, -0.4649, -0.4649, -0.4649,\n",
      "          0.0226,  0.0226,  0.0226,  0.0226, -0.4545, -0.4545, -0.4545, -0.4545],\n",
      "        [ 0.6708,  0.6708,  0.6708,  0.6708,  1.0076,  1.0076,  1.0076,  1.0076,\n",
      "          0.2219,  0.2219,  0.2219,  0.2219, -0.7537, -0.7537, -0.7537, -0.7537,\n",
      "         -0.0854, -0.0854, -0.0854, -0.0854,  0.5190,  0.5190,  0.5190,  0.5190,\n",
      "          1.0275,  1.0275,  1.0275,  1.0275, -0.4649, -0.4649, -0.4649, -0.4649,\n",
      "          0.0226,  0.0226,  0.0226,  0.0226, -0.4545, -0.4545, -0.4545, -0.4545],\n",
      "        [ 0.6708,  0.6708,  0.6708,  0.6708,  1.0076,  1.0076,  1.0076,  1.0076,\n",
      "          0.2219,  0.2219,  0.2219,  0.2219, -0.7537, -0.7537, -0.7537, -0.7537,\n",
      "         -0.0854, -0.0854, -0.0854, -0.0854,  0.5190,  0.5190,  0.5190,  0.5190,\n",
      "          1.0275,  1.0275,  1.0275,  1.0275, -0.4649, -0.4649, -0.4649, -0.4649,\n",
      "          0.0226,  0.0226,  0.0226,  0.0226, -0.4545, -0.4545, -0.4545, -0.4545],\n",
      "        [ 0.6708,  0.6708,  0.6708,  0.6708,  1.0076,  1.0076,  1.0076,  1.0076,\n",
      "          0.2219,  0.2219,  0.2219,  0.2219, -0.7537, -0.7537, -0.7537, -0.7537,\n",
      "         -0.0854, -0.0854, -0.0854, -0.0854,  0.5190,  0.5190,  0.5190,  0.5190,\n",
      "          1.0275,  1.0275,  1.0275,  1.0275, -0.4649, -0.4649, -0.4649, -0.4649,\n",
      "          0.0226,  0.0226,  0.0226,  0.0226, -0.4545, -0.4545, -0.4545, -0.4545],\n",
      "        [ 0.6708,  0.6708,  0.6708,  0.6708,  1.0076,  1.0076,  1.0076,  1.0076,\n",
      "          0.2219,  0.2219,  0.2219,  0.2219, -0.7537, -0.7537, -0.7537, -0.7537,\n",
      "         -0.0854, -0.0854, -0.0854, -0.0854,  0.5190,  0.5190,  0.5190,  0.5190,\n",
      "          1.0275,  1.0275,  1.0275,  1.0275, -0.4649, -0.4649, -0.4649, -0.4649,\n",
      "          0.0226,  0.0226,  0.0226,  0.0226, -0.4545, -0.4545, -0.4545, -0.4545],\n",
      "        [ 0.6708,  0.6708,  0.6708,  0.6708,  1.0076,  1.0076,  1.0076,  1.0076,\n",
      "          0.2219,  0.2219,  0.2219,  0.2219, -0.7537, -0.7537, -0.7537, -0.7537,\n",
      "         -0.0854, -0.0854, -0.0854, -0.0854,  0.5190,  0.5190,  0.5190,  0.5190,\n",
      "          1.0275,  1.0275,  1.0275,  1.0275, -0.4649, -0.4649, -0.4649, -0.4649,\n",
      "          0.0226,  0.0226,  0.0226,  0.0226, -0.4545, -0.4545, -0.4545, -0.4545]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[ 0.2890],\n",
      "        [ 0.2220],\n",
      "        [ 0.1822],\n",
      "        [-0.0443],\n",
      "        [ 0.0357],\n",
      "        [ 0.2336],\n",
      "        [ 0.1591],\n",
      "        [-0.2304],\n",
      "        [ 0.1195],\n",
      "        [-0.1302]])\n",
      "torch.Size([12, 1, 10])\n",
      "torch.Size([12, 40])\n"
     ]
    }
   ],
   "source": [
    "input = torch.ones(12, 1, 10)\n",
    "weights_layer1 = net.cnn_layers[0].weight.data\n",
    "print(weights_layer1)\n",
    "print(weights_layer1.shape)\n",
    "output = net(input)\n",
    "print(input)\n",
    "print(output)\n",
    "print(weights_layer1[:,:,0])\n",
    "print(input.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Sequential( \n",
    "                        nn.Conv1d(1, 10, 5), # layer1\n",
    "                        nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(\n",
    "                       nn.Conv2d(10, 4, 5), # layer2\n",
    "                       nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return self.conv2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "weights_layer1 = model.conv1[0].weight.data # gets weights\n",
    "bias_layer1 = model.conv1[0].bias.data # gets bias\n",
    "weights_layer2 = model.conv2[0].weight.data\n",
    "bias_layer2 = model.conv2[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1046, -0.1366, -0.1460, -0.1997,  0.1916],\n",
      "          [-0.0780,  0.1427,  0.1885,  0.1805,  0.1439],\n",
      "          [ 0.1106, -0.1603,  0.0782, -0.0258,  0.0378],\n",
      "          [ 0.0158,  0.0701,  0.0895,  0.1202,  0.0768],\n",
      "          [ 0.1853, -0.1200,  0.0739,  0.0320, -0.0553]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0601, -0.0608,  0.1187,  0.1572, -0.1100],\n",
      "          [ 0.1423,  0.0539,  0.0793,  0.1080,  0.0103],\n",
      "          [-0.0223, -0.0622,  0.0910, -0.0497,  0.0365],\n",
      "          [-0.1323,  0.0813, -0.0198, -0.1515,  0.1989],\n",
      "          [ 0.0090, -0.0420,  0.0278, -0.0127,  0.1119]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0246, -0.0263, -0.1701, -0.0424, -0.0364],\n",
      "          [ 0.1188,  0.1074,  0.1133,  0.1900, -0.0446],\n",
      "          [ 0.1270, -0.0677,  0.0932,  0.0298,  0.1894],\n",
      "          [-0.1926,  0.0753,  0.0453,  0.1944, -0.0063],\n",
      "          [-0.0287,  0.0822, -0.1902, -0.0052, -0.1631]]],\n",
      "\n",
      "\n",
      "        [[[-0.0190, -0.0729, -0.1857,  0.1380,  0.1343],\n",
      "          [ 0.0229,  0.0517, -0.0449, -0.1380, -0.1816],\n",
      "          [-0.1221, -0.0666, -0.0257,  0.0749,  0.0797],\n",
      "          [ 0.0232, -0.0935, -0.1922, -0.1264, -0.0795],\n",
      "          [ 0.1002, -0.1908,  0.1182,  0.0661, -0.1304]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0776, -0.1814,  0.0181, -0.1048,  0.1642],\n",
      "          [ 0.1151, -0.1619,  0.1845,  0.1443, -0.1358],\n",
      "          [ 0.1295, -0.1784, -0.0664,  0.0098, -0.1570],\n",
      "          [-0.0247, -0.0338,  0.0018, -0.1218, -0.0975],\n",
      "          [-0.1495, -0.1076,  0.1408, -0.0225, -0.0117]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0851, -0.1822, -0.1759, -0.0918, -0.1774],\n",
      "          [ 0.1264, -0.0596,  0.0410, -0.0779, -0.1447],\n",
      "          [-0.1598,  0.0690, -0.1895,  0.0901, -0.0505],\n",
      "          [-0.0099,  0.1857, -0.0504,  0.1685, -0.0383],\n",
      "          [ 0.0579, -0.1570,  0.0004, -0.1154, -0.0769]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1186, -0.0470, -0.0613, -0.0453,  0.1626],\n",
      "          [ 0.0794, -0.0192, -0.0393, -0.1369,  0.0420],\n",
      "          [ 0.1337, -0.1762,  0.0721,  0.0168,  0.1425],\n",
      "          [-0.1221,  0.0929, -0.0878, -0.1539, -0.0814],\n",
      "          [ 0.1464,  0.0163,  0.1095,  0.0583,  0.0030]]],\n",
      "\n",
      "\n",
      "        [[[-0.0141, -0.1813, -0.1019,  0.1334,  0.0794],\n",
      "          [-0.0159,  0.1378, -0.1761, -0.1319, -0.1671],\n",
      "          [ 0.1895, -0.0467, -0.0282, -0.1246,  0.1545],\n",
      "          [-0.1637,  0.1498, -0.1196,  0.1589, -0.0785],\n",
      "          [ 0.0374, -0.1595,  0.1912,  0.1767, -0.1572]]],\n",
      "\n",
      "\n",
      "        [[[-0.1514,  0.0181, -0.1440, -0.1478,  0.1709],\n",
      "          [-0.1706,  0.1824, -0.0263, -0.0442, -0.1106],\n",
      "          [-0.1849,  0.0791,  0.1399,  0.1114,  0.0990],\n",
      "          [ 0.0681,  0.1783,  0.1100, -0.1281,  0.1252],\n",
      "          [ 0.0463,  0.1738,  0.0339, -0.1057, -0.0401]]],\n",
      "\n",
      "\n",
      "        [[[-0.1290,  0.0503, -0.0256, -0.1794,  0.0606],\n",
      "          [ 0.1715, -0.0174, -0.0098,  0.1549, -0.0836],\n",
      "          [ 0.0265,  0.0800, -0.1000, -0.1960,  0.0489],\n",
      "          [ 0.1694, -0.1825, -0.1092,  0.0901,  0.1919],\n",
      "          [-0.0520,  0.0737,  0.1243, -0.1484, -0.0480]]]])\n"
     ]
    }
   ],
   "source": [
    "print(weights_layer1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('aimodel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92e33a288536da9adb44c7ac0c478613f4f1d2d7e0a7333f782d56ab9a7d2711"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
